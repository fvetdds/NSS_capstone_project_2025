{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88c9f1-17e5-43b4-9452-66efd07b0d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 805us/step\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 916us/step\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 745us/step\n",
      "Trial 1/10: prec=0.1534 ← {'learning_rate': 0.0001, 'hidden_units': 32, 'epochs': 30, 'dropout_rate': 0.2, 'batch_size': 32}\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "\u001b[1m2876/2876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 723us/step\n",
      "Trial 2/10: prec=0.1807 ← {'learning_rate': 0.0005, 'hidden_units': 16, 'epochs': 50, 'dropout_rate': 0.1, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    precision_score, precision_recall_curve, average_precision_score,\n",
    "    classification_report, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "# --- Load & split ---\n",
    "df = pd.read_csv(\"bcsc_concatenated_no_9.csv\")\n",
    "X = df.drop(columns=\"breast_cancer_history\")\n",
    "y = df[\"breast_cancer_history\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Class weights matching your XGB setup ---\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "pos_penalty_factor = 10.0\n",
    "w_neg = 1.0\n",
    "w_pos = scale_pos_weight * pos_penalty_factor\n",
    "\n",
    "def weighted_bce(y_true, y_pred):\n",
    "    w = y_true * w_pos + (1 - y_true) * w_neg\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(w * bce)\n",
    "\n",
    "# --- Model factory ---\n",
    "def create_model(hidden_units, dropout_rate, learning_rate):\n",
    "    m = Sequential()\n",
    "    # define input shape with Input layer\n",
    "    m.add(Input(shape=(X_train.shape[1],)))\n",
    "    m.add(Dense(hidden_units, activation=\"relu\"))\n",
    "    m.add(Dropout(dropout_rate))\n",
    "    m.add(Dense(hidden_units // 2, activation=\"relu\"))\n",
    "    m.add(Dropout(dropout_rate))\n",
    "    m.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    m.compile(\n",
    "        loss=weighted_bce,\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"AUC\"]\n",
    "    )\n",
    "    return m\n",
    "\n",
    "# --- Hyperparameter space & sampler ---\n",
    "param_dist = {\n",
    "    \"hidden_units\":   [16, 32, 64],\n",
    "    \"dropout_rate\":   [0.1, 0.2, 0.3],\n",
    "    \"learning_rate\":  [1e-3, 5e-4, 1e-4],\n",
    "    \"epochs\":         [30, 50],\n",
    "    \"batch_size\":     [16, 32],\n",
    "}\n",
    "\n",
    "n_iter = 10\n",
    "random.seed(42)\n",
    "sampler = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "# --- 3-fold stratified CV to pick best params by precision at default 0.5 ---\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for idx, params in enumerate(sampler, 1):\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = create_model(\n",
    "            hidden_units=params[\"hidden_units\"],\n",
    "            dropout_rate=params[\"dropout_rate\"],\n",
    "            learning_rate=params[\"learning_rate\"]\n",
    "        )\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            epochs=params[\"epochs\"],\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            verbose=0\n",
    "        )\n",
    "        y_pred = model.predict(X_val).flatten()\n",
    "        y_cls = (y_pred >= 0.5).astype(int)\n",
    "        cv_scores.append(precision_score(y_val, y_cls))\n",
    "    \n",
    "    mean_prec = np.mean(cv_scores)\n",
    "    print(f\"Trial {idx}/{n_iter}: prec={mean_prec:.4f} ← {params}\")\n",
    "    if mean_prec > best_score:\n",
    "        best_score, best_params = mean_prec, params\n",
    "\n",
    "print(\"\\nBest params (by CV precision):\")\n",
    "print(best_params, \"→ precision\", best_score)\n",
    "\n",
    "# --- Retrain on full train set with EarlyStopping ---\n",
    "model = create_model(\n",
    "    hidden_units=best_params[\"hidden_units\"],\n",
    "    dropout_rate=best_params[\"dropout_rate\"],\n",
    "    learning_rate=best_params[\"learning_rate\"]\n",
    ")\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- Get probabilities on test set ---\n",
    "y_prob = model.predict(X_test).flatten()\n",
    "\n",
    "# --- Precision–Recall analysis & threshold selection ---\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "avg_prec = average_precision_score(y_test, y_prob)\n",
    "\n",
    "target_prec = 0.7\n",
    "valid = np.where(precision >= target_prec)[0]\n",
    "if valid.size:\n",
    "    i = valid[np.argmax(recall[valid])]\n",
    "    thr = thresholds[i if i < thresholds.size else -1]\n",
    "    print(f\"\\nAt precision ≥ {target_prec:.2f}, threshold={thr:.3f}, \"\n",
    "          f\"prec={precision[i]:.3f}, recall={recall[i]:.3f}\")\n",
    "else:\n",
    "    thr = 0.5\n",
    "    print(f\"\\nNo threshold achieves precision ≥ {target_prec:.2f}, defaulting to 0.5\")\n",
    "\n",
    "# --- Plot PR curve ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recall, precision, marker='.', label=f'NN (AP={avg_prec:.2f})')\n",
    "if valid.size:\n",
    "    plt.scatter(recall[i], precision[i], color='red',\n",
    "                label=f'P={precision[i]:.2f}, R={recall[i]:.2f}, Thr={thr:.2f}')\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True); plt.legend(); plt.show()\n",
    "\n",
    "# --- Final eval at chosen threshold ---\n",
    "y_pred = (y_prob >= thr).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"Matthews Corr Coef:\", matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "# --- Save artifacts ---\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/bcsc_nn_model2.h5\")\n",
    "joblib.dump(thr, \"models/threshold2.pkl\")\n",
    "print(\"\\nModel and threshold saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512aee58-f27b-4494-8bd8-8072e534e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d28e6-9532-4d11-8045-50bf2592b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"METABRIC_removedgene.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "df['status_combo'] = (\n",
    "    df['er_status'].astype(str) + '_' +\n",
    "    df['pr_status'].astype(str) + '_' +\n",
    "    df['her2_status'].astype(str)\n",
    ")\n",
    "\n",
    "df['survival_group'] = np.where(\n",
    "    df['overall_survival_months'] <= 72, \n",
    "    1, \n",
    "    2\n",
    ")\n",
    "\n",
    "avg_survival = (\n",
    "    df.groupby('status_combo')['overall_survival_months']\n",
    "      .mean()\n",
    "      .reset_index(name='avg_survival_months')\n",
    ")\n",
    "avg_survival = avg_survival.sort_values('avg_survival_months')\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(\n",
    "    avg_survival['status_combo'],\n",
    "    avg_survival['avg_survival_months']\n",
    ")\n",
    "plt.xlabel('ER/PR/HER2 Status Combination')\n",
    "plt.ylabel('Average Overall Survival (months)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Average Overall Survival by ER/PR/HER2 Combination')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883c09b-87ba-4a46-9627-1cbd476d8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load & clean\n",
    "df = pd.read_csv(\"METABRIC_removedgene.csv\")\n",
    "df = df.dropna(subset=['er_status', 'pr_status', 'her2_status', 'age_at_diagnosis'])\n",
    "\n",
    "# Build combo and survival group (if still needed)\n",
    "df['status_combo'] = (\n",
    "    df['er_status'].astype(str) + '_' +\n",
    "    df['pr_status'].astype(str) + '_' +\n",
    "    df['her2_status'].astype(str)\n",
    ")\n",
    "df['survival_group'] = np.where(\n",
    "    df['overall_survival_months'] <= 72, 1, 2\n",
    ")\n",
    "\n",
    "# Compute average age by combo\n",
    "avg_age = (\n",
    "    df.groupby('status_combo')['age_at_diagnosis']\n",
    "      .mean()\n",
    "      .reset_index(name='avg_age_years')\n",
    "      .sort_values('avg_age_years')\n",
    ")\n",
    "\n",
    "# Plot bar chart in sorted order\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(\n",
    "    avg_age['status_combo'],\n",
    "    avg_age['avg_age_years']\n",
    ")\n",
    "plt.xlabel('ER/PR/HER2 Status Combination')\n",
    "plt.ylabel('Average Age at Diagnosis (years)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Average Age at Diagnosis by ER/PR/HER2 Combination')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1531dc-8a9a-49a9-9e3d-a61aa49d1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (classification_report,roc_auc_score,confusion_matrix,matthews_corrcoef,make_scorer,precision_score,precision_recall_curve,average_precision_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Load and split data \n",
    "df = pd.read_csv(\"bcsc_concatenated_no_9.csv\")\n",
    "X = df.drop(columns=\"breast_cancer_history\")\n",
    "y = df[\"breast_cancer_history\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Compute class weights\n",
    "scale_pos_weight = len(y_train[y_train==0])/len(y_train[y_train==1])\n",
    "pos_penalty_factor = 10.0\n",
    "weight_neg = 1.0\n",
    "weight_pos = scale_pos_weight*pos_penalty_factor\n",
    "def weighted_logloss(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    \n",
    "    \n",
    "    p = 1.0 / (1.0 + np.exp(-y_pred))\n",
    "    \n",
    "    w = np.where(y_true == 1, weight_pos, weight_neg)\n",
    "    \n",
    "    grad = w * (p - y_true)\n",
    "    hess = w * p * (1.0 - p)\n",
    "    return grad, hess\n",
    "\n",
    "# Hyperparameter search setup\n",
    "penalized_clf = xgb.XGBClassifier(\n",
    "    objective=weighted_logloss,\n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\":     [100, 300, 500],\n",
    "    \"max_depth\":        [3, 5, 7],\n",
    "    \"learning_rate\":    [0.01, 0.05, 0.1],\n",
    "    \"subsample\":        [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\":            [0, 1, 5],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=penalized_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=make_scorer(precision_score, pos_label=1),\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Run hyperparameter search ---\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", search.best_params_)\n",
    "\n",
    "# Retrain on full training set ---\n",
    "best = search.best_estimator_\n",
    "best.fit(X_train, y_train)\n",
    "\n",
    "# Compute test‐set probabilities ---\n",
    "y_prob = best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Precision‐Recall analysis ---\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_prob)\n",
    "avg_prec = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# pick threshold at precision ≥ 0.7\n",
    "target_precision = 0.7\n",
    "valid = np.where(precision >= target_precision)[0]\n",
    "if len(valid) > 0:\n",
    "    best_idx = valid[np.argmax(recall[valid])]\n",
    "    matched_precision = precision[best_idx]\n",
    "    matched_recall = recall[best_idx]\n",
    "    matched_threshold = pr_thresholds[\n",
    "        best_idx if best_idx < len(pr_thresholds) else -1\n",
    "    ]\n",
    "    print(f\"At precision ≥ {target_precision:.2f}:\")\n",
    "    print(f\"  Precision: {matched_precision:.3f}\")\n",
    "    print(f\"  Recall:    {matched_recall:.3f}\")\n",
    "    print(f\"  Threshold: {matched_threshold:.3f}\")\n",
    "else:\n",
    "    print(f\"No recall point found where precision ≥ {target_precision:.2f}\")\n",
    "    # plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.', label=f'XGBoost (AP={avg_prec:.2f})')\n",
    "plt.scatter(\n",
    "    [matched_recall],\n",
    "    [matched_precision],\n",
    "    color='red',\n",
    "    label=(\n",
    "        f'Precision={matched_precision:.2f}\\n'\n",
    "        f'Recall={matched_recall:.2f}\\n'\n",
    "        f'Threshold={matched_threshold:.2f}'\n",
    "    )\n",
    ")\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Final evaluation at chosen threshold ---\n",
    "best_thresh = matched_threshold\n",
    "y_pred = (y_prob >= best_thresh).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nTest ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n",
    "# --- Feature importances ---\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feat_imp_df)\n",
    "\n",
    "# plot top 15 feature importances\n",
    "top_n = 15\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "feat_imp_df.head(top_n).plot.barh(x='feature', y='importance', legend=False, ax=ax)\n",
    "plt.title('Top Feature Importances (XGBoost)')\n",
    "plt.xlabel('Importance Score')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importance_xgb.jpg\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --- Save model & threshold ---\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(best, os.path.join(\"models\", \"bcsc_xgb_model.pkl\"))\n",
    "joblib.dump(best_thresh, os.path.join(\"models\", \"threshold.pkl\"))\n",
    "print(\"Model and threshold saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb2017-63cd-4ada-ae28-303461165f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# — Load your external validation set —\n",
    "# Replace with your actual data source\n",
    "X_val = pd.read_csv(\"external_X_val.csv\")            # features\n",
    "y_val = pd.read_csv(\"external_y_val.csv\")[\"target\"]   # 0/1 labels\n",
    "\n",
    "# — Get predicted probabilities —\n",
    "# Assuming you've already loaded your trained XGBoost model as `model`\n",
    "y_prob = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# — Compute calibration curve —\n",
    "# `n_bins` can be tuned; 10–20 is typical\n",
    "prob_true, prob_pred = calibration_curve(y_val, y_prob, n_bins=10, strategy=\"uniform\")\n",
    "\n",
    "# — Plot it —\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label=\"Calibration curve\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label=\"Perfect calibration\")\n",
    "plt.xlabel(\"Mean predicted probability\")\n",
    "plt.ylabel(\"Fraction of positives\")\n",
    "plt.title(\"Calibration Curve (External Validation)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# — Compute Brier score —\n",
    "brier = brier_score_loss(y_val, y_prob)\n",
    "print(f\"Brier score: {brier:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
