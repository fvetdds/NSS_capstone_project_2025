{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10e79d-c840-4db7-8b2c-8006d778781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: scikeras in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vetdd\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow scikeras scikit-learn\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    precision_score, precision_recall_curve, average_precision_score,\n",
    "    classification_report, roc_auc_score, confusion_matrix, matthews_corrcoef\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.backend as K\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "# --- Load & split ---\n",
    "df = pd.read_csv(\"bcsc_concatenated_no_9.csv\")\n",
    "X = df.drop(columns=\"breast_cancer_history\")\n",
    "y = df[\"breast_cancer_history\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Class weights matching your XGB setup ---\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "pos_penalty_factor = 10.0\n",
    "w_neg = 1.0\n",
    "w_pos = scale_pos_weight * pos_penalty_factor\n",
    "\n",
    "def weighted_bce(y_true, y_pred):\n",
    "    w = y_true * w_pos + (1 - y_true) * w_neg\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    return K.mean(w * bce)\n",
    "\n",
    "# --- Model factory ---\n",
    "def create_model(hidden_units, dropout_rate, learning_rate):\n",
    "    m = Sequential([\n",
    "        Dense(hidden_units, activation=\"relu\", input_dim=X_train.shape[1]),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(hidden_units // 2, activation=\"relu\"),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ])\n",
    "    m.compile(\n",
    "        loss=weighted_bce,\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"AUC\"]\n",
    "    )\n",
    "    return m\n",
    "\n",
    "# --- Hyperparameter space & sampler ---\n",
    "param_dist = {\n",
    "    \"hidden_units\":   [16, 32, 64],\n",
    "    \"dropout_rate\":   [0.1, 0.2, 0.3],\n",
    "    \"learning_rate\":  [1e-3, 5e-4, 1e-4],\n",
    "    \"epochs\":         [30, 50],\n",
    "    \"batch_size\":     [16, 32],\n",
    "}\n",
    "\n",
    "n_iter = 10\n",
    "random.seed(42)\n",
    "sampler = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "# --- 3-fold stratified CV to pick best params by precision at default 0.5 ---\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "\n",
    "for idx, params in enumerate(sampler, 1):\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        model = create_model(\n",
    "            hidden_units=params[\"hidden_units\"],\n",
    "            dropout_rate=params[\"dropout_rate\"],\n",
    "            learning_rate=params[\"learning_rate\"]\n",
    "        )\n",
    "        # no early stopping in CV\n",
    "        model.fit(\n",
    "            X_tr, y_tr,\n",
    "            epochs=params[\"epochs\"],\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            verbose=0\n",
    "        )\n",
    "        y_pred = model.predict(X_val).flatten()\n",
    "        y_cls = (y_pred >= 0.5).astype(int)\n",
    "        cv_scores.append(precision_score(y_val, y_cls))\n",
    "    \n",
    "    mean_prec = np.mean(cv_scores)\n",
    "    print(f\"Trial {idx}/{n_iter}: prec={mean_prec:.4f} ← {params}\")\n",
    "    if mean_prec > best_score:\n",
    "        best_score, best_params = mean_prec, params\n",
    "\n",
    "print(\"\\nBest params (by CV precision):\")\n",
    "print(best_params, \"→ precision\", best_score)\n",
    "\n",
    "# --- Retrain on full train set with EarlyStopping ---\n",
    "model = create_model(\n",
    "    hidden_units=best_params[\"hidden_units\"],\n",
    "    dropout_rate=best_params[\"dropout_rate\"],\n",
    "    learning_rate=best_params[\"learning_rate\"]\n",
    ")\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    validation_split=0.2,\n",
    "    callbacks=[es],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# --- Get probabilities on test set ---\n",
    "y_prob = model.predict(X_test).flatten()\n",
    "\n",
    "# --- Precision‐Recall analysis & threshold selection ---\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "avg_prec = average_precision_score(y_test, y_prob)\n",
    "\n",
    "target_prec = 0.7\n",
    "valid = np.where(precision >= target_prec)[0]\n",
    "if valid.size:\n",
    "    i = valid[np.argmax(recall[valid])]\n",
    "    thr = thresholds[i if i < thresholds.size else -1]\n",
    "    print(f\"\\nAt precision ≥ {target_prec:.2f}, threshold={thr:.3f}, \"\n",
    "          f\"prec={precision[i]:.3f}, recall={recall[i]:.3f}\")\n",
    "else:\n",
    "    thr = 0.5\n",
    "    print(f\"\\nNo threshold achieves precision ≥ {target_prec:.2f}, defaulting to 0.5\")\n",
    "\n",
    "# --- Plot PR curve ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recall, precision, marker='.', label=f'NN (AP={avg_prec:.2f})')\n",
    "if valid.size:\n",
    "    plt.scatter(recall[i], precision[i], color='red',\n",
    "                label=f'P={precision[i]:.2f}, R={recall[i]:.2f}, Thr={thr:.2f}')\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True); plt.legend(); plt.show()\n",
    "\n",
    "# --- Final eval at chosen threshold ---\n",
    "y_pred = (y_prob >= thr).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"Matthews Corr Coef:\", matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "# --- Save artifacts ---\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model.save(\"models/bcsc_nn_model.h5\")\n",
    "joblib.dump(thr, \"models/threshold.pkl\")\n",
    "print(\"\\nModel and threshold saved.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512aee58-f27b-4494-8bd8-8072e534e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d28e6-9532-4d11-8045-50bf2592b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(\"METABRIC_removedgene.csv\")\n",
    "df = df.dropna()\n",
    "\n",
    "df['status_combo'] = (\n",
    "    df['er_status'].astype(str) + '_' +\n",
    "    df['pr_status'].astype(str) + '_' +\n",
    "    df['her2_status'].astype(str)\n",
    ")\n",
    "\n",
    "df['survival_group'] = np.where(\n",
    "    df['overall_survival_months'] <= 72, \n",
    "    1, \n",
    "    2\n",
    ")\n",
    "\n",
    "avg_survival = (\n",
    "    df.groupby('status_combo')['overall_survival_months']\n",
    "      .mean()\n",
    "      .reset_index(name='avg_survival_months')\n",
    ")\n",
    "avg_survival = avg_survival.sort_values('avg_survival_months')\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(\n",
    "    avg_survival['status_combo'],\n",
    "    avg_survival['avg_survival_months']\n",
    ")\n",
    "plt.xlabel('ER/PR/HER2 Status Combination')\n",
    "plt.ylabel('Average Overall Survival (months)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Average Overall Survival by ER/PR/HER2 Combination')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883c09b-87ba-4a46-9627-1cbd476d8b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load & clean\n",
    "df = pd.read_csv(\"METABRIC_removedgene.csv\")\n",
    "df = df.dropna(subset=['er_status', 'pr_status', 'her2_status', 'age_at_diagnosis'])\n",
    "\n",
    "# Build combo and survival group (if still needed)\n",
    "df['status_combo'] = (\n",
    "    df['er_status'].astype(str) + '_' +\n",
    "    df['pr_status'].astype(str) + '_' +\n",
    "    df['her2_status'].astype(str)\n",
    ")\n",
    "df['survival_group'] = np.where(\n",
    "    df['overall_survival_months'] <= 72, 1, 2\n",
    ")\n",
    "\n",
    "# Compute average age by combo\n",
    "avg_age = (\n",
    "    df.groupby('status_combo')['age_at_diagnosis']\n",
    "      .mean()\n",
    "      .reset_index(name='avg_age_years')\n",
    "      .sort_values('avg_age_years')\n",
    ")\n",
    "\n",
    "# Plot bar chart in sorted order\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(\n",
    "    avg_age['status_combo'],\n",
    "    avg_age['avg_age_years']\n",
    ")\n",
    "plt.xlabel('ER/PR/HER2 Status Combination')\n",
    "plt.ylabel('Average Age at Diagnosis (years)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Average Age at Diagnosis by ER/PR/HER2 Combination')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1531dc-8a9a-49a9-9e3d-a61aa49d1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (classification_report,roc_auc_score,confusion_matrix,matthews_corrcoef,make_scorer,precision_score,precision_recall_curve,average_precision_score\n",
    ")\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Load and split data \n",
    "df = pd.read_csv(\"bcsc_concatenated_no_9.csv\")\n",
    "X = df.drop(columns=\"breast_cancer_history\")\n",
    "y = df[\"breast_cancer_history\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Compute class weights\n",
    "scale_pos_weight = len(y_train[y_train==0])/len(y_train[y_train==1])\n",
    "pos_penalty_factor = 10.0\n",
    "weight_neg = 1.0\n",
    "weight_pos = scale_pos_weight*pos_penalty_factor\n",
    "def weighted_logloss(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    \n",
    "    \n",
    "    p = 1.0 / (1.0 + np.exp(-y_pred))\n",
    "    \n",
    "    w = np.where(y_true == 1, weight_pos, weight_neg)\n",
    "    \n",
    "    grad = w * (p - y_true)\n",
    "    hess = w * p * (1.0 - p)\n",
    "    return grad, hess\n",
    "\n",
    "# Hyperparameter search setup\n",
    "penalized_clf = xgb.XGBClassifier(\n",
    "    objective=weighted_logloss,\n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\":     [100, 300, 500],\n",
    "    \"max_depth\":        [3, 5, 7],\n",
    "    \"learning_rate\":    [0.01, 0.05, 0.1],\n",
    "    \"subsample\":        [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"gamma\":            [0, 1, 5],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=penalized_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring=make_scorer(precision_score, pos_label=1),\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "# Run hyperparameter search ---\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", search.best_params_)\n",
    "\n",
    "# Retrain on full training set ---\n",
    "best = search.best_estimator_\n",
    "best.fit(X_train, y_train)\n",
    "\n",
    "# Compute test‐set probabilities ---\n",
    "y_prob = best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Precision‐Recall analysis ---\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_prob)\n",
    "avg_prec = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# pick threshold at precision ≥ 0.7\n",
    "target_precision = 0.7\n",
    "valid = np.where(precision >= target_precision)[0]\n",
    "if len(valid) > 0:\n",
    "    best_idx = valid[np.argmax(recall[valid])]\n",
    "    matched_precision = precision[best_idx]\n",
    "    matched_recall = recall[best_idx]\n",
    "    matched_threshold = pr_thresholds[\n",
    "        best_idx if best_idx < len(pr_thresholds) else -1\n",
    "    ]\n",
    "    print(f\"At precision ≥ {target_precision:.2f}:\")\n",
    "    print(f\"  Precision: {matched_precision:.3f}\")\n",
    "    print(f\"  Recall:    {matched_recall:.3f}\")\n",
    "    print(f\"  Threshold: {matched_threshold:.3f}\")\n",
    "else:\n",
    "    print(f\"No recall point found where precision ≥ {target_precision:.2f}\")\n",
    "    # plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.', label=f'XGBoost (AP={avg_prec:.2f})')\n",
    "plt.scatter(\n",
    "    [matched_recall],\n",
    "    [matched_precision],\n",
    "    color='red',\n",
    "    label=(\n",
    "        f'Precision={matched_precision:.2f}\\n'\n",
    "        f'Recall={matched_recall:.2f}\\n'\n",
    "        f'Threshold={matched_threshold:.2f}'\n",
    "    )\n",
    ")\n",
    "plt.xlabel('Recall', fontsize=14)\n",
    "plt.ylabel('Precision', fontsize=14)\n",
    "plt.title('Precision-Recall Curve', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Final evaluation at chosen threshold ---\n",
    "best_thresh = matched_threshold\n",
    "y_pred = (y_prob >= best_thresh).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nTest ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(y_test, y_pred))\n",
    "# --- Feature importances ---\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feat_imp_df)\n",
    "\n",
    "# plot top 15 feature importances\n",
    "top_n = 15\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "feat_imp_df.head(top_n).plot.barh(x='feature', y='importance', legend=False, ax=ax)\n",
    "plt.title('Top Feature Importances (XGBoost)')\n",
    "plt.xlabel('Importance Score')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importance_xgb.jpg\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# --- Save model & threshold ---\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(best, os.path.join(\"models\", \"bcsc_xgb_model.pkl\"))\n",
    "joblib.dump(best_thresh, os.path.join(\"models\", \"threshold.pkl\"))\n",
    "print(\"Model and threshold saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb2017-63cd-4ada-ae28-303461165f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
